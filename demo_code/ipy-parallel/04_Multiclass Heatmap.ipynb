{
 "metadata": {
  "name": "",
  "signature": "sha256:e3264b8dd427ee64750044e95da9e4b0a4457a4af83b55e172b6614bb9b2dd71"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "cli = Client()\n",
      "print(\"Total workers: {}\".format(len(cli.ids)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total workers: 12\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview = cli[:]\n",
      "lbview = cli.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "from collections import Counter, namedtuple\n",
      "import itertools\n",
      "from pathlib import Path\n",
      "import pickle\n",
      "\n",
      "from IPython.html import widgets # Widget definitions\n",
      "from IPython.display import display # Used to display widgets in the notebook\n",
      "\n",
      "from PIL import Image\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn import svm\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "current_dir = Path('.').resolve().as_posix()\n",
      "src_dir = Path('../../src').resolve().as_posix()\n",
      "dview['current_dir'] = current_dir\n",
      "dview['src_dir'] = src_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "import sys\n",
      "sys.path.append(current_dir)\n",
      "sys.path.append(src_dir)\n",
      "from exp_utils import (\n",
      "    Connection, Dataset, SingleLabelDataset,\n",
      "    PathConnection, DatasetConnection, \n",
      "    TrainTestConnection, TrainTestDatsetConnection,\n",
      "    Pred, get_mismatch_pred, make_mismatch_df, confmat_to_df, read_patches_from_batch\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Label mapping"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "with pd.ExcelFile(\n",
      "    str(Path(current_dir).parent / 'exp06_both' / 'label_mapping_modified.xlsx')\n",
      ") as xlsx:\n",
      "    label_stat_df = TrainTestConnection(xlsx.parse('Train'), xlsx.parse('Test'))\n",
      "    \n",
      "IGNORE_LABELS = [-1, 6, 7]\n",
      "def make_label_map(df):\n",
      "    return {\n",
      "        fsuf: lab\n",
      "        for fsuf, lab in zip(df.file_suffix, df.label)\n",
      "        if lab not in IGNORE_LABELS\n",
      "    }\n",
      "anno_label_map = label_stat_df.apply(make_label_map)\n",
      "\n",
      "LABEL_NAME_MAP = {\n",
      "    1: '\u817a\u764c', 2: '\u6b63\u5e38', 3: '\u7c98\u6db2\u764c', 4: '\u952f\u9f7f\u72b6\u764c',\n",
      "    5: '\u4e73\u5934\u72b6\u764c', 6: '\u7ed2\u6bdb\u72b6\u817a\u7624', 7: '\u952f\u9f7f\u72b6\u817a\u7624', 8: '\u7ef8\u5e26\u7c89\u523a\u72b6\u764c',    \n",
      "}\n",
      "LABEL_NAME_MAP_EN= {\n",
      "    1: 'AC', 2: 'N', 3: 'MC', 4: 'SC',\n",
      "    5: 'PC', 6: 'VA', 7: 'SA', 8: 'CCTA'\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "train = Dataset(\n",
      "    dir_name='exp04_run', img_desc_pth=str(Path(current_dir).parent / 'exp04_run/remote_train_list.txt'),\n",
      "    anno_label_map=anno_label_map.train\n",
      ")\n",
      "test = Dataset(\n",
      "    dir_name='exp05_run', img_desc_pth=str(Path(current_dir).parent / 'exp05_run/remote_test_list.txt'),\n",
      "    anno_label_map=anno_label_map.test\n",
      ")\n",
      "addnorm = SingleLabelDataset(\n",
      "    label=2,\n",
      "    dir_name='exp08_addnorm', img_desc_pth=str(Path(current_dir).parent /'exp08_addnorm/normal_list_0.txt')\n",
      ")\n",
      "all_datasets = TrainTestDatsetConnection(train=train, test=test, addnorm=addnorm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat_df_avg_softmax3 = all_datasets.used_features.apply(\n",
      "    lambda feat_mat: pd.DataFrame(np.r_[f[0], f[2]] for f in feat_mat))\n",
      "feat_df_avg_softmax3.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "Connection(train=(273, 8192), test=(120, 8192), addnorm=(300, 8192))"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_X = np.concatenate(list(feat_df_avg_softmax3))\n",
      "full_Y = np.concatenate(list(all_datasets.used_labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ss_splitter = cross_validation.StratifiedShuffleSplit(\n",
      "    full_Y, n_iter=1, test_size=0.5, random_state=9527\n",
      ")\n",
      "train_ix, test_ix = next(iter(ss_splitter))\n",
      "\n",
      "train_X, train_Y = full_X[train_ix], full_Y[train_ix]\n",
      "test_X, test_Y = full_X[test_ix], full_Y[test_ix]\n",
      "\n",
      "classifier = svm.LinearSVC(C=0.5, random_state=5566)\n",
      "classifier.fit(train_X, train_Y)\n",
      "\n",
      "weight_mat = classifier.coef_\n",
      "weight_mat.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(6, 8192)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LABEL_NAME = [LABEL_NAME_MAP_EN[cls] for cls in classifier.classes_]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "import matplotlib as mpl\n",
      "mpl.use(\"Agg\")\n",
      "\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib import gridspec\n",
      "from matplotlib import font_manager\n",
      "from matplotlib.colors import Normalize\n",
      "from matplotlib.ticker import MaxNLocator\n",
      "from mpl_toolkits.axes_grid1 import make_axes_locatable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "class MidpointNormalize(Normalize):\n",
      "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
      "        self.midpoint = midpoint\n",
      "        Normalize.__init__(self, vmin, vmax, clip)\n",
      "\n",
      "    def __call__(self, value, clip=None):\n",
      "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
      "        # simple example...\n",
      "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
      "        # masking value too low\n",
      "        # norm_value = np.interp(value, x, y)\n",
      "        # white_cond = (0.45 < norm_value) & (norm_value < 0.55)\n",
      "        # return np.ma.masked_where(white_cond, norm_value)\n",
      "        norm_arr = np.interp(value, x, y)\n",
      "        return np.ma.masked_array(norm_arr, mask=np.isnan(norm_arr))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out_root = Path(\n",
      "    r\"\\\\msralab\\ProjectData\\eHealth\\v-lianwa\\CRC_pathology_result\\exp10_refinefig\"\n",
      "    r\"\\heatmap_multilabel_separate_jet\"\n",
      ")\n",
      "if not out_root.exists():\n",
      "    out_root.mkdir(parents=True)\n",
      "\n",
      "out_root_test = out_root / 'test'\n",
      "out_root_train = out_root / 'train'\n",
      "out_root_addnorm = out_root / 'addnorm'\n",
      "for out_dir in [out_root_test, out_root_train, out_root_addnorm]:\n",
      "    if not out_dir.exists():\n",
      "        out_dir.mkdir()\n",
      "    for class_label in LABEL_NAME:\n",
      "        cls_subdir = out_dir / class_label\n",
      "        if not cls_subdir.exists():\n",
      "            cls_subdir.mkdir(parents=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def read_batch(p):\n",
      "    with p.open('rb') as f:\n",
      "        img_batch_map = pickle.load(f)\n",
      "    return img_batch_map\n",
      "\n",
      "img_batch_map = TrainTestConnection(\n",
      "    train=read_batch(all_datasets.train.img_batch_pickle),\n",
      "    test=read_batch(all_datasets.test.img_batch_pickle),\n",
      "    addnorm=None\n",
      ")\n",
      "\n",
      "### img_batch_map for addnorm\n",
      "batch_dir_addnorm = all_datasets.addnorm.result_root / 'batch'\n",
      "batch_list_addnorm = sorted(\n",
      "    (p for p in batch_dir_addnorm.iterdir() if p.name.startswith('data_batch')),\n",
      "    key=lambda p: int(p.name.rsplit('_', 1)[-1])\n",
      ")\n",
      "img_batch_map.addnorm = dict(\n",
      "    (k, list(v)) \n",
      "    for k, v in itertools.groupby(\n",
      "        batch_list_addnorm, \n",
      "        lambda p: int(p.name.rsplit('_', 1)[-1]) // 1000\n",
      "    ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar = dview.push(dict(\n",
      "    out_root_test=out_root_test, out_root_train=out_root_train, out_root_addnorm=out_root_addnorm,\n",
      "    LABEL_NAME=LABEL_NAME, LABEL_NAME_MAP=LABEL_NAME_MAP, LABEL_NAME_MAP_EN=LABEL_NAME_MAP_EN,\n",
      "    weight_mat=weight_mat\n",
      "))\n",
      "ar.wait()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def read_patches_from_batch_addnorm(img_id, img_batch_map):\n",
      "    img_data = []\n",
      "    feat_vec = []\n",
      "    for batch_p in img_batch_map[img_id]:\n",
      "        with batch_p.open('rb') as f:\n",
      "            raw = pickle.load(f, encoding='latin1')\n",
      "        img_data.extend(\n",
      "            data_vec for data_vec, lab in zip(raw['data'], raw['labels'])\n",
      "            if lab == 0\n",
      "        )\n",
      "        feat_vec.extend(\n",
      "            fc2_vec for fc2_vec, lab in zip(raw['fc2'], raw['labels'])\n",
      "            if lab == 0\n",
      "        )\n",
      "    return img_data, feat_vec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def plot_class_confidence_separate(\n",
      "    img_id, img_patches, img_pth, label_name, dist_mat, fig_out_p\n",
      "):\n",
      "    \"\"\"Plot two plot, original figure and heatmap\"\"\"\n",
      "    # open instance image\n",
      "    instance_img = Image.open(img_pth.open('rb'))\n",
      "    orig_size = instance_img.size\n",
      "    \n",
      "    # resize\n",
      "    instance_img.thumbnail((4096, 4096), Image.ANTIALIAS)\n",
      "    current_size = instance_img.size\n",
      "    scale_x = current_size[0] / orig_size[0]\n",
      "    scale_y = current_size[1] / orig_size[1]\n",
      "    \n",
      "    ## Draw orig fig\n",
      "    # orig_fig_pth = fig_out_p.parent / (fig_out_p.stem + '_orig.png')\n",
      "    # fig = plt.figure(None, (8, 8))\n",
      "    # plt.imshow(instance_img, interpolation='nearest')\n",
      "    # plt.axis('off')\n",
      "    # fig.savefig(str(orig_fig_pth), transparent=True, bbox_inches='tight', pad_inches=0, dpi=300)\n",
      "    # plt.close(fig)\n",
      "    \n",
      "    ##  Draw heatmap\n",
      "    fig = plt.figure(None, (8, 8), frameon=False)\n",
      "    ax = fig.add_subplot(1, 1, 1)\n",
      "    # make the confidence matrix\n",
      "    confid_mat = np.zeros(current_size, np.float32)\n",
      "    confid_count = np.zeros(current_size, np.int)\n",
      "    # confid_vec = dist_mat[0, :]\n",
      "    confid_vec = next(\n",
      "        confid_vec for class_label, confid_vec in zip(LABEL_NAME, dist_mat)\n",
      "        if class_label == label_name\n",
      "    )\n",
      "    for confid, patch in zip(confid_vec, img_patches):\n",
      "        margin = patch.window.to_margin()\n",
      "        slice_x = slice(np.round(margin.x1 * scale_x), np.round(margin.x2 * scale_x))\n",
      "        slice_y = slice(np.round(margin.y1 * scale_y), np.round(margin.y2 * scale_y))\n",
      "        confid_mat[slice_x, slice_y] += confid\n",
      "        confid_count[slice_x, slice_y] += 1\n",
      "    confid_count = np.where(confid_count == 0, np.nan, confid_count)\n",
      "    confid_mat /= confid_count\n",
      "    # plot heatmap\n",
      "    norm = MidpointNormalize(midpoint=0)\n",
      "    cmap = plt.cm.jet  # plt.cm.RdYlBu_r\n",
      "    # cmap.set_bad(color='w', alpha=0)\n",
      "    ax.imshow(instance_img, interpolation='nearest', aspect='equal')\n",
      "    im_confid = ax.imshow(\n",
      "        confid_mat.T, interpolation='nearest', norm=norm, origin='upper',\n",
      "        alpha=0.4, cmap=cmap, aspect='equal'\n",
      "    )\n",
      "    # turn off borders\n",
      "    ax.set_axis_off()\n",
      "    plt.axis('off')\n",
      "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
      "    fig.savefig(str(fig_out_p), transparent=True, bbox_inches='tight', pad_inches=0, dpi=600)\n",
      "    plt.close(fig)\n",
      "    return fig_out_p    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def plot_class_confidence(\n",
      "    img_id, img_patches, img_pth, label_name, dist_mat, fig_out_p\n",
      "):   \n",
      "    # open instance image\n",
      "    instance_img = Image.open(img_pth.open('rb'))\n",
      "    orig_size = instance_img.size\n",
      "    \n",
      "    # resize\n",
      "    instance_img.thumbnail((4096, 4096), Image.ANTIALIAS)\n",
      "    instance_img.thumbnail((2048, 2048), Image.ANTIALIAS)\n",
      "    # instance_img.thumbnail((1024, 1024), Image.ANTIALIAS)\n",
      "\n",
      "    current_size = instance_img.size\n",
      "    scale_x = current_size[0] / orig_size[0]\n",
      "    scale_y = current_size[1] / orig_size[1]\n",
      "    \n",
      "    # Begin drawing\n",
      "    fig = plt.figure(None, (16, 8))\n",
      "    gs_all = gridspec.GridSpec(1, 2)\n",
      "\n",
      "    # orig fig\n",
      "    ax_orig = plt.subplot(gs_all[:2, 0])\n",
      "    ax_orig.imshow(instance_img)\n",
      "    ax_orig.axis('off')\n",
      "    # ax_orig.set_title(\"Image {:d} (Class {:s})\".format(img_id, label_name), fontproperties=chs_font)\n",
      "    ax1 = plt.subplot(gs_all[0, 1])\n",
      "\n",
      "    for class_label, confid_vec in zip(LABEL_NAME, dist_mat):\n",
      "        if class_label != label_name:\n",
      "            continue\n",
      "        # make the confidence matrix\n",
      "        confid_mat = np.zeros(current_size)\n",
      "        confid_count = np.zeros(current_size, np.int)\n",
      "        for confid, patch in zip(confid_vec, img_patches):\n",
      "            margin = patch.window.to_margin()\n",
      "            slice_x = slice(np.round(margin.x1 * scale_x), np.round(margin.x2 * scale_x))\n",
      "            slice_y = slice(np.round(margin.y1 * scale_y), np.round(margin.y2 * scale_y))\n",
      "            confid_mat[slice_x, slice_y] += confid\n",
      "            confid_count[slice_x, slice_y] += 1\n",
      "        confid_count = np.where(confid_count == 0, np.nan, confid_count)\n",
      "        confid_mat /= confid_count\n",
      "        \n",
      "        # plot orig image\n",
      "        ax1.imshow(instance_img)\n",
      "        # plot heatmap\n",
      "        norm = MidpointNormalize(midpoint=0)\n",
      "        im_confid = ax1.imshow(confid_mat.T, norm=norm, alpha=0.6, origin='upper', cmap=plt.cm.RdYlBu_r)\n",
      "        # im_confid = ax1.imshow(confid_mat.T, norm=norm, alpha=0.4, origin='upper', cmap=plt.cm.jet)\n",
      "        \n",
      "        # setting\n",
      "        # ax.set_title(\"Class {:s} vs rest\".format(class_label), fontproperties=chs_font)\n",
      "        ax1.axis('off')\n",
      "    \n",
      "    # save figure\n",
      "    fig.savefig(str(fig_out_p), transparent=True, bbox_inches='tight', pad_inches=0.1, dpi=300)\n",
      "    plt.close(fig)\n",
      "    return fig_out_p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@lbview.parallel(block=False)\n",
      "def plot_test_class_confidence(img_id):\n",
      "    # print(\"Processing test image\", img_id)\n",
      "    img_data, img_patch_feats = read_patches_from_batch(img_id, img_batch_map.test)\n",
      "    # print(\"Getting total {:d} patches\".format(len(img_patch_feats)))\n",
      "    img_patch_feat_mat = np.tile(img_patch_feats, [1, 2])\n",
      "    dist_mat = weight_mat.dot(img_patch_feat_mat.T)  # comput the distance (confidence) value\n",
      "    \n",
      "    # read patch\n",
      "    patch_pickle_p = Path(all_datasets.test.result_root, 'patch',  str(img_id), 'patch_records.pickle3') \n",
      "    \n",
      "    with patch_pickle_p.open('rb') as f:\n",
      "        img_patches = [p for p in pickle.load(f) if not any(p.window.outmargin)]\n",
      "    img_pth = all_datasets.test.img_paths[img_id]\n",
      "\n",
      "    label_name = LABEL_NAME_MAP_EN[all_datasets.test.labels[img_id]]\n",
      "    fig_out_p = Path(out_root_test, label_name, \"Image_{:d}.png\".format(img_id))\n",
      "    return plot_class_confidence_separate(\n",
      "        img_id, img_patches, img_pth, label_name, dist_mat, fig_out_p\n",
      "    )\n",
      "\n",
      "\n",
      "@lbview.parallel(block=False)\n",
      "def plot_train_class_confidence(img_id):\n",
      "    # print(\"Processing test image\", img_id)\n",
      "    img_data, img_patch_feats = read_patches_from_batch(img_id, img_batch_map.train)\n",
      "    # print(\"Getting total {:d} patches\".format(len(img_patch_feats)))\n",
      "    img_patch_feat_mat = np.tile(img_patch_feats, [1, 2])\n",
      "    dist_mat = weight_mat.dot(img_patch_feat_mat.T)  # comput the distance (confidence) value\n",
      "    \n",
      "    # read patch\n",
      "    patch_pickle_p = Path(all_datasets.train.result_root, 'patch',  str(img_id), 'patch_records.pickle3') \n",
      "    \n",
      "    with patch_pickle_p.open('rb') as f:\n",
      "        img_patches = [p for p in pickle.load(f) if not any(p.window.outmargin)]\n",
      "    img_pth = all_datasets.train.img_paths[img_id]\n",
      "\n",
      "    label_name = LABEL_NAME_MAP_EN[all_datasets.train.labels[img_id]]\n",
      "    fig_out_p = Path(out_root_train, label_name, \"Image_{:d}.png\".format(img_id))\n",
      "    return plot_class_confidence_separate(\n",
      "        img_id, img_patches, img_pth, label_name, dist_mat, fig_out_p\n",
      "    )\n",
      "\n",
      "\n",
      "@lbview.parallel(block=False)\n",
      "def plot_addnorm_class_confidence(img_id):\n",
      "    # print(\"Processing test image\", img_id)\n",
      "    img_data, img_patch_feats = read_patches_from_batch_addnorm(img_id, img_batch_map.addnorm)\n",
      "    # print(\"Getting total {:d} patches\".format(len(img_patch_feats)))\n",
      "    img_patch_feat_mat = np.tile(img_patch_feats, [1, 2])\n",
      "    dist_mat = weight_mat.dot(img_patch_feat_mat.T)  # comput the distance (confidence) value\n",
      "    \n",
      "    # read patch\n",
      "    patch_pickle_p = Path(all_datasets.addnorm.result_root, 'patch',  str(img_id), 'patch_records.pickle3') \n",
      "    \n",
      "    with patch_pickle_p.open('rb') as f:\n",
      "        img_patches = [p for p in pickle.load(f) if not any(p.window.outmargin)]\n",
      "    img_pth = all_datasets.addnorm.img_paths[img_id]\n",
      "\n",
      "    label_name = LABEL_NAME_MAP_EN[2]\n",
      "    fig_out_p = Path(out_root_addnorm, label_name, \"Image_{:d}.png\".format(img_id))\n",
      "    return plot_class_confidence_separate(\n",
      "        img_id, img_patches, img_pth, label_name, dist_mat, fig_out_p\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from IPython import display as ipydisplay"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "fig_p = PathConnection(train=None, test=None, addnorm=None)\n",
      "fig_p.train = plot_train_class_confidence.func(13)\n",
      "fig_p.addnorm = plot_addnorm_class_confidence.func(10)\n",
      "fig_p.test = plot_test_class_confidence.func(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:py.warnings:C:\\Miniconda\\envs\\crc34\\lib\\site-packages\\PIL\\Image.py:2192: DecompressionBombWarning: Image size (205051824 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
        "  DecompressionBombWarning)\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wall time: 3min 12s\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ipydisplay.Image(str(fig_p.train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Run all images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_async_meta(async_result, out_pth):\n",
      "    \"\"\"Save async result meta to pickle\"\"\"\n",
      "    ar_meta_df = pd.DataFrame(async_result.metadata)\n",
      "    ar_meta_df = ar_meta_df[\n",
      "        ['engine_id', 'engine_uuid', 'msg_id', 'started', 'completed', 'received']]\n",
      "    ar_meta_df.to_pickle(str(out_pth))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar = plot_train_class_confidence.map(all_datasets.train.used_img_ids)\n",
      "ar.wait_interactive()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 273/273 tasks finished after 1104 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_async_meta(ar, out_root / 'train_ar_meta.pickle3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar = plot_test_class_confidence.map(all_datasets.test.used_img_ids)\n",
      "ar.wait_interactive()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120/120 tasks finished after 1250 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_async_meta(ar, out_root / 'test_ar_meta.pickle3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar = plot_addnorm_class_confidence.map(all_datasets.addnorm.used_img_ids)\n",
      "ar.wait_interactive()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 300/300 tasks finished after 1835 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_async_meta(ar, out_root / 'addnorm_ar_meta.pickle3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}
